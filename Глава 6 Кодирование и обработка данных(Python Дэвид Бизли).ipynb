{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глава 6 Кодирование и обработка данных(Python Дэвид Бизли)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная тема этой главы — использование Python для обработки данных, представленных в различных типах распространенных форматов, таких как файлы\n",
    "CSV, JSON, XML и упакованные бинарные записи. \n",
    "\n",
    "В отличие от главы о структурах\n",
    "данных, здесь мы не будем фокусироваться на конкретных алгоритмах, а рассмотрим задачу получения данных из программы и передачи данных в программу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение и запись данных в формате CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы хотите прочесть или записать данные в CSV-файл.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для большей части CSV-данных можно использовать библиотеку csv. Предположим, что у вас есть данные о рынке акций в файле stocks.csv:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Symbol,Price,Date,Time,Change,Volume\n",
    "\"AA\",39.48,\"6/11/2007\",\"9:36am\",-0.18,181800\n",
    "\"AIG\",71.38,\"6/11/2007\",\"9:36am\",-0.15,195500\n",
    "\"AXP\",62.58,\"6/11/2007\",\"9:36am\",-0.46,935000\n",
    "\"BA\",98.31,\"6/11/2007\",\"9:36am\",+0.12,104800\n",
    "\"C\",53.08,\"6/11/2007\",\"9:36am\",-0.25,360900\n",
    "\"CAT\",78.29,\"6/11/2007\",\"9:36am\",-0.23,225400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот как вы могли бы прочитать данные в последовательность кортежей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800']\n",
      "['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500']\n",
      "['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000']\n",
      "['BA', '98.31', '6/11/2007', '9:36am', '+0.12', '104800']\n",
      "['C', '53.08', '6/11/2007', '9:36am', '-0.25', '360900']\n",
      "['CAT', '78.29', '6/11/2007', '9:36am', '-0.23', '225400']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В приведенном выше коде строке соответствует кортеж. Поэтому для доступа\n",
    "к определенному полю вам нужно использовать индексирование: row[0] (Symbol)\n",
    "и row[4] (Change)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку такое индексирование часто может быть запутанным, вы можете захотеть использовать именованные кортежи. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Symbol='AA', Price='39.48', Date='6/11/2007', Time='9:36am', Change='-0.18', Volume='181800')\n",
      "Row(Symbol='AIG', Price='71.38', Date='6/11/2007', Time='9:36am', Change='-0.15', Volume='195500')\n",
      "Row(Symbol='AXP', Price='62.58', Date='6/11/2007', Time='9:36am', Change='-0.46', Volume='935000')\n",
      "Row(Symbol='BA', Price='98.31', Date='6/11/2007', Time='9:36am', Change='+0.12', Volume='104800')\n",
      "Row(Symbol='C', Price='53.08', Date='6/11/2007', Time='9:36am', Change='-0.25', Volume='360900')\n",
      "Row(Symbol='CAT', Price='78.29', Date='6/11/2007', Time='9:36am', Change='-0.23', Volume='225400')\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headings = next(f_csv)\n",
    "    Row = namedtuple('Row', headings)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это позволит использовать вместо индексов заголовки колонок, такие как \n",
    "\n",
    "row.Symbol и row.Change. \n",
    "\n",
    "Стоит отметить, что это сработает только в том случае, если\n",
    "заголовки колонок являются валидными идентификаторами Python. \n",
    "\n",
    "Если это не\n",
    "так, вы должны будете обработать эти заголовки (например, заменить неподходящие символы подчеркиваниями или аналогичными).\n",
    "\n",
    "Еще одна альтернатива – прочесть данные в виде последовательности словарей. Чтобы это сделать, используйте такой код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Symbol', 'AA'), ('Price', '39.48'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.18'), ('Volume', '181800')])\n",
      "OrderedDict([('Symbol', 'AIG'), ('Price', '71.38'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.15'), ('Volume', '195500')])\n",
      "OrderedDict([('Symbol', 'AXP'), ('Price', '62.58'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.46'), ('Volume', '935000')])\n",
      "OrderedDict([('Symbol', 'BA'), ('Price', '98.31'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '+0.12'), ('Volume', '104800')])\n",
      "OrderedDict([('Symbol', 'C'), ('Price', '53.08'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.25'), ('Volume', '360900')])\n",
      "OrderedDict([('Symbol', 'CAT'), ('Price', '78.29'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.23'), ('Volume', '225400')])\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "    for row in f_csv:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой версии вы можете обращаться к элементам каждой строки, используя\n",
    "заголовки строки. \n",
    "\n",
    "Например, row['Symbol'] или row['Change'].\n",
    "\n",
    "Чтобы записать данные в  CSV, вы также можете использовать модуль csv, но\n",
    "создавая объект writer. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Symbol','Price','Date','Time','Change','Volume']\n",
    "rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n",
    "        ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),\n",
    "        ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000),]\n",
    "\n",
    "with open('stocks1.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Если у вас есть данные в форме последовательности словарей, сделайте так:\n",
    "headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
    "rows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.18, 'Volume':181800},\n",
    " {'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.15, 'Volume': 195500},\n",
    " {'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.46, 'Volume': 935000},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stocks2.csv','w') as f:\n",
    "    f_csv = csv.DictWriter(f, headers)\n",
    "    f_csv.writeheader()\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы должны практически всегда предпочитать модуль csv ручному разрезанию\n",
    "и парсингу CSV-данных. \n",
    "\n",
    "Например, вы можете просто написать такой код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stocks.csv') as f:\n",
    "    for line in f:\n",
    "        row = line.split(',')\n",
    " # Обработка строки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема подобного подхода в том, что придется разбираться с надоедливыми\n",
    "деталями. \n",
    "\n",
    "Например, если одно из полей окружено кавычками, вы должны будете\n",
    "их срезать. \n",
    "\n",
    "А если это закавыченное поле содержит запятую, код сломается, поскольку выдаст строку неверного размера.\n",
    "\n",
    "По умолчанию библиотека csv запрограммирована понимать правила кодирования CSV, которые используются Microsoft Excel. \n",
    "\n",
    "Это, вероятно, наиболее распространенный вариант, и он с высокой вероятностью обеспечит вам наилучшую\n",
    "совместимость. \n",
    "\n",
    "Однако вы можете свериться с документацией модуля csv, и там\n",
    "вы найдете настройки, которые помогут работать с кодировками другого формата\n",
    "(например, заменить символ-разделитель и т. п.) Например, если вы хотите прочесть данные, разделенные символами табуляции, используйте вот такой код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример чтения разделенных символом табуляции значений\n",
    "with open('stock.tsv') as f:\n",
    "    f_tsv = csv.reader(f, delimiter='\\t')\n",
    "    for row in f_tsv:\n",
    "    # Обработка строки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы читаете данные в CSV и конвертируете их в именованные кортежи, вам\n",
    "нужно быть аккуратными с валидацией заголовков колонок.\n",
    "\n",
    "Например, CSV-файл\n",
    "может иметь строку заголовка, содержащую невалидный символ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Street Address,Num-Premises,Latitude,Longitude\n",
    "5412 N CLARK,10,41.980262,-87.668452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это при создании экземпляра namedtuple возбудит исключение ValueError. Чтобы обойти проблему, вам может потребоваться почистить заголовки. Например,\n",
    "разобраться с невалидными символами с помощью регулярного выражения:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open('stock.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = [ re.sub('[^a-zA-Z_]', '_', h) for h in next(f_csv) ]\n",
    "    Row = namedtuple('Row', headers)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        # Обработка строки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно отметить, что модуль csv не пытается интерпретировать данные или\n",
    "конвертировать их в какой-то другой тип, нежели строку. Если такие преобразования нужны, их вам придется выполнить самостоятельно. Вот пример выполнения\n",
    "дополнительных преобразований типов CSV-данных:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_types = [str, float, str, str, float, int]\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "     # Применение преобразований к элементам строки\n",
    "     row = tuple(convert(value) for convert, value in zip(col_types, row))\n",
    " ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативный пример преобразования выбранных полей словарей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reading as dicts with type conversion')\n",
    "field_types = [ ('Price', float), ('Change', float), ('Volume', int) ]\n",
    "with open('stocks.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        row.update((key, conversion(row[key])) for key, conversion in field_types)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем, вам стоит быть осторожными с такими преобразованиями. \n",
    "\n",
    "В реальном мире в CSV-файлах часто попадаются отсутствующие поля, поврежденные\n",
    "данные и прочие проблемы, которые могут поломать преобразования типов. \n",
    "\n",
    "Так что если ваши данные не являются гарантированно безошибочными, об этом стоит помнить (например, вы можете добавить подходящую обработку исключений).\n",
    "\n",
    "Наконец, если ваша цель – чтение CSV-данных для выполнения анализа данных\n",
    "и статистических расчетов, вы можете взглянуть на пакет Pandas. \n",
    "\n",
    "Pandas включает удобную функцию pandas.read_csv(), которая загружает CSV-данные в объект\n",
    "DataFrame. \n",
    "\n",
    "Далее вы можете провести различные статистические расчеты, отфильтровать данные и выполнить другие высокоуровневые операции. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение и запись в формате JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы хотите прочитать или записать данные, закодированные в  JSON (JavaScript\n",
    "Object Notation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модуль json предоставляет простой способ кодировать и  декодировать данные\n",
    "в JSON. Две главные функции – json.dumps() и json.loads() – соответствуют интерфейсу других библиотек для сериализации, таких как pickle. \n",
    "\n",
    "Вот как вы можете\n",
    "превратить структуру данных Python в JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"ACME\", \"shares\": 100, \"price\": 542.23}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = {\n",
    " 'name' : 'ACME',\n",
    " 'shares' : 100,\n",
    " 'price' : 542.23\n",
    "}\n",
    "#сериализация\n",
    "json_str = json.dumps(data)\n",
    "print(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот как можно превратить строку в JSON обратно в структуру данных Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'ACME', 'shares': 100, 'price': 542.23}\n"
     ]
    }
   ],
   "source": [
    "# Запись JSON-данных\n",
    "with open('data_json.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "# Чтение данных\n",
    "with open('data_json.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодирование в JSON поддерживает базовые типы: None, bool, int, float, str, – а также списки, кортежи и словари, содержащие эти типы. \n",
    "\n",
    "В случае словарей ключами\n",
    "должны быть строки (все нестроковые ключи будут преобразованы в строки во\n",
    "время кодирования). \n",
    "\n",
    "Чтобы соответствовать спецификации JSON, вы должны кодировать только списки и словари Python. Более того, для веб-приложений стандартной практикой является использование именно словарей в качестве объектов верхнего уровня.\n",
    "\n",
    "Формат JSON практически идентичен синтаксису Python, за исключением нескольких небольших изменений. \n",
    "\n",
    "Например, True отображается на true, False – на\n",
    "false, а None – на null. Вот пример того, как выглядят закодированные данные:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a': True, 'b': 'Hello', 'c': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"a\": true, \"b\": \"Hello\", \"c\": null}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите изучить данные, которые вы раскодировали из JSON, часто бывает трудно установить их структуру путем простого вывода, особенно если присутствует многоуровневая вложенность или большое количество различных полей. \n",
    "\n",
    "Чтобы справиться с  этой задачей, попробуйте функцию pprint() из модуля\n",
    "pprint. \n",
    "\n",
    "Она расположит ключи в алфавитном порядке и выведет словарь в более\n",
    "понятном виде. \n",
    "\n",
    "Вот пример того, как вы можете симпатично вывести результаты\n",
    "поиска по Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "u = urlopen('http://search.twitter.com/search.json?q=python&rpp=5')\n",
    "resp = json.loads(u.read().decode('utf-8'))\n",
    "from pprint import pprint\n",
    "pprint(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'completed_in': 0.074,\n",
    "'max_id': 264043230692245504,\n",
    "'max_id_str': '264043230692245504',\n",
    "'next_page': '?page=2&max_id=264043230692245504&q=python&rpp=5',\n",
    "'page': 1,\n",
    "'query': 'python',\n",
    "'refresh_url': '?since_id=264043230692245504&q=python',\n",
    "'results': [{'created_at': 'Thu, 01 Nov 2012 16:36:26 +0000',\n",
    " 'from_user': ...\n",
    "},\n",
    " {'created_at': 'Thu, 01 Nov 2012 16:36:14 +0000',\n",
    " 'from_user': ...\n",
    " },\n",
    " {'created_at': 'Thu, 01 Nov 2012 16:36:13 +0000',\n",
    " 'from_user': ...\n",
    " },\n",
    " {'created_at': 'Thu, 01 Nov 2012 16:36:07 +0000',\n",
    " 'from_user': ...\n",
    " }\n",
    " {'created_at': 'Thu, 01 Nov 2012 16:36:04 +0000',\n",
    " 'from_user': ...\n",
    " }],\n",
    " 'results_per_page': 5,\n",
    " 'since_id': 0,\n",
    " 'since_id_str': '0'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обычном случае декодирование JSON создаст из предоставленных данных\n",
    "словари или списки. \n",
    "\n",
    "Если вы хотите создать другие объекты, передайте objects_pair_hook или object_hook функции json.loads().\n",
    "\n",
    "Например, вы можете декодировать\n",
    "JSON-данные, сохраняя их порядок в OrderedDict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "data = json.loads(s, object_pairs_hook=OrderedDict)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот как вы можете превратить словарь JSON в объект Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d =  {'name': 'ACME', 'shares': 50, 'price': 490.1}\n"
     ]
    }
   ],
   "source": [
    "class JSONObject:\n",
    "    def __init__(self, d):\n",
    "        print('d = ', d)\n",
    "        self.__dict__ = d\n",
    "\n",
    "data = json.loads(s, object_hook=JSONObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACME'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490.1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последнем примере созданный при декодировании JSON-данных словарь\n",
    "передается как единственный аргумент в __init__(). Далее вы можете использовать\n",
    "его, как хотите, в том числе и напрямую в качестве экземпляра словаря объекта.\n",
    "\n",
    "Есть несколько параметров, которые могут быть полезны при кодировании\n",
    "в JSON. Если вы хотите, чтобы вывод был симпатично отформатирован, то можете использовать аргумент indent функции json.dumps(). \n",
    "\n",
    "В этом случае вывод будет\n",
    "красиво выводиться – в формате, похожем на вывод фунции pprint(). Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"ACME\",\n",
      "    \"shares\": 50,\n",
      "    \"price\": 490.1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите, чтобы при выводе происходила сортировка ключей, используйте аргумент sort_keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"ACME\", \"price\": 490.1, \"shares\": 50}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Экземпляры в обычном случае не являются сериализуемыми. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Point is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-e93da69829e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m--> 179\u001b[1;33m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[0;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type Point is not JSON serializable"
     ]
    }
   ],
   "source": [
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "p = Point(2, 3)\n",
    "json.dumps(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите сериализовать экземпляры, то можете предоставить функцию,\n",
    "которая принимает экземпляр на вход и возвращает словарь, который может быть\n",
    "сериализован. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_instance(obj):\n",
    "    d = { '__classname__' : type(obj).__name__ }\n",
    "    d.update(vars(obj))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите получить экземпляр обратно, то можете сделать это так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь отображения имен на известные классы\n",
    "classes = {\n",
    " 'Point' : Point\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unserialize_object(d):\n",
    "    clsname = d.pop('__classname__', None)\n",
    "    if clsname:\n",
    "        cls = classes[clsname]\n",
    "        obj = cls.__new__(cls) # Создание экземпляра без вызова __init__\n",
    "        for key, value in d.items():\n",
    "            setattr(obj, key, value)\n",
    "        return obj\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот пример того, как используются эти функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"__classname__\": \"Point\", \"x\": 2, \"y\": 3}'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Point(2,3)\n",
    "s = json.dumps(p, default=serialize_instance)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Point at 0x1ad583368d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = json.loads(s, object_hook=unserialize_object)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'x',\n",
       " 'y']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В модуле json множество других возможностей для контроля низкоуровневой\n",
    "интерпретации чисел, специальных значений (таких как NaN) и т. п. Обратитесь\n",
    "к документации за подробностями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Парсинг простых XML-данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы хотите извлечь данные из простого XML-документа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модуль xml.etree.ElementTree может быть использован для извлечения данных из\n",
    "простых XML-документов. \n",
    "\n",
    "Чтобы продемонстрировать это, предположим, что вы\n",
    "хотите распарсить и подготовить выжимку RSS-канала Planet Python. Вот скрипт,\n",
    "который это сделает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mike Driscoll: PyDev of the Week: Sebastián Ramírez\n",
      "Mon, 20 Jan 2020 06:05:33 +0000\n",
      "http://www.blog.pythonlibrary.org/2020/01/20/pydev-of-the-week-sebastian-ramirez/\n",
      "\n",
      "IslandT: Link together the Tkinter user interface and database Input class\n",
      "Mon, 20 Jan 2020 06:04:10 +0000\n",
      "https://kibiwebgeek.com/link-together-the-tkinter-user-interface-and-database-input-class/\n",
      "\n",
      "Ionel Cristian Maries: Is there anything safe in python?\n",
      "Sun, 19 Jan 2020 22:00:00 +0000\n",
      "https://blog.ionelmc.ro/2020/01/20/is-there-anything-safe-in-python/\n",
      "\n",
      "Codementor: How To Publish Your Own Python Package\n",
      "Sun, 19 Jan 2020 21:48:24 +0000\n",
      "https://www.codementor.io/ajayagrawal295/how-to-publish-your-own-python-package-12tbhi20tf\n",
      "\n",
      "Simple is Better Than Complex: How to Use Chart.js with Django\n",
      "Sun, 19 Jan 2020 15:00:00 +0000\n",
      "https://simpleisbetterthancomplex.com/tutorial/2020/01/19/how-to-use-chart-js-with-django.html\n",
      "\n",
      "Weekly Python StackOverflow Report: (ccxi) stackoverflow python report\n",
      "Sun, 19 Jan 2020 12:01:00 +0000\n",
      "http://python-weekly.blogspot.com/2020/01/ccxi-stackoverflow-python-report.html\n",
      "\n",
      "Python Circle: How to set a variable in Django template\n",
      "Sun, 19 Jan 2020 07:46:08 +0000\n",
      "https://www.pythoncircle.com/post/701/how-to-set-a-variable-in-django-template/\n",
      "\n",
      "Python Circle: Encryption-Decryption in Python Django\n",
      "Sun, 19 Jan 2020 07:46:08 +0000\n",
      "https://www.pythoncircle.com/post/641/encryption-decryption-in-python-django/\n",
      "\n",
      "Python Circle: Top 5 Python Books\n",
      "Sun, 19 Jan 2020 07:46:08 +0000\n",
      "https://www.pythoncircle.com/post/646/top-5-python-books/\n",
      "\n",
      "Codementor: Why ASGI is Replacing WSGI in Django\n",
      "Sun, 19 Jan 2020 05:31:20 +0000\n",
      "https://www.codementor.io/maxongzb/why-asgi-is-replacing-wsgi-in-django-reading-time-3-mins-12slef6mjc\n",
      "\n",
      "Peter Hoffmann: Understand predicate pushdown on row group level in Parquet with pyarrow and python\n",
      "Sun, 19 Jan 2020 00:00:00 +0000\n",
      "http://peter-hoffmann.com/2020/understand-predicate-pushdown-on-rowgroup-level-in-parquet-with-pyarrow-and-python.html\n",
      "\n",
      "Python Circle: How to display flash messages in Django templates\n",
      "Sat, 18 Jan 2020 19:46:23 +0000\n",
      "https://www.pythoncircle.com/post/700/how-to-display-flash-messages-in-django-templates/\n",
      "\n",
      "Catalin George Festila: Python 3.7.5 : Django security issues - part 001.\n",
      "Sat, 18 Jan 2020 06:48:56 +0000\n",
      "http://python-catalin.blogspot.com/2020/01/python-375-django-security-issues-part.html\n",
      "\n",
      "Catalin George Festila: Python 3.7.5 : Is Django the best web framework?\n",
      "Sat, 18 Jan 2020 06:14:18 +0000\n",
      "http://python-catalin.blogspot.com/2019/12/python-375-is-django-best-web-framework.html\n",
      "\n",
      "IslandT: Create the input text box with tkinter\n",
      "Sat, 18 Jan 2020 04:45:18 +0000\n",
      "https://kibiwebgeek.com/create-the-input-text-box-with-tkinter/\n",
      "\n",
      "Peter Bengtsson: JavaScript destructuring like Python kwargs with defaults\n",
      "Sat, 18 Jan 2020 02:59:14 +0000\n",
      "https://www.peterbe.com/plog/javascript-destructuring-like-python-kwargs-with-defaults\n",
      "\n",
      "PyCon: The 9th Annual PyLadies Auction\n",
      "Fri, 17 Jan 2020 20:00:27 +0000\n",
      "https://pycon.blogspot.com/2020/01/the-9th-annual-pyladies-auction.html\n",
      "\n",
      "Tim Arnold / reachtim: Reading Binary Data with Python\n",
      "Fri, 17 Jan 2020 16:48:07 +0000\n",
      "https://reachtim.com/articles/reading-binary-data-with-python.html\n",
      "\n",
      "Codementor: How to Build RESTful APIs with Python and Flask\n",
      "Fri, 17 Jan 2020 16:05:55 +0000\n",
      "https://www.codementor.io/dongido/how-to-build-restful-apis-with-python-and-flask-12qto530jd\n",
      "\n",
      "Python Software Foundation: Start using 2FA and API tokens on PyPI\n",
      "Fri, 17 Jan 2020 15:06:23 +0000\n",
      "http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/3wzQ4odyH-4/start-using-2fa-and-api-tokens-on-pypi.html\n",
      "\n",
      "PyPy Development: Leysin Winter sprint 2020: Feb 28 - March 7th\n",
      "Fri, 17 Jan 2020 11:37:59 +0000\n",
      "http://feedproxy.google.com/~r/PyPyStatusBlog/~3/NIBXnG16Ucc/leysin-winter-sprint-2020-feb-28-march.html\n",
      "\n",
      "py.CheckIO: Mocking in Python\n",
      "Thu, 16 Jan 2020 17:09:38 +0000\n",
      "http://py.checkio.org/blog/mocking-python/\n",
      "\n",
      "Stack Abuse: Variable-Length Arguments in Python with *args and **kwargs\n",
      "Thu, 16 Jan 2020 13:32:00 +0000\n",
      "https://stackabuse.com/variable-length-arguments-in-python-with-args-and-kwargs/\n",
      "\n",
      "Codementor: Build REST API with Flask &amp; SQLAlchemy\n",
      "Thu, 16 Jan 2020 09:05:53 +0000\n",
      "https://www.codementor.io/rhmnfadhil/build-rest-api-with-flask-sqlalchemy-12pcrvdv83\n",
      "\n",
      "Talk Python to Me: #247 Solo maintainer of open-source in academia\n",
      "Thu, 16 Jan 2020 08:00:00 +0000\n",
      "https://talkpython.fm/episodes/show/247/solo-maintainer-of-open-source-in-academia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "# Скачивание и парсинг RSS-канала\n",
    "u = urlopen('http://planet.python.org/rss20.xml')\n",
    "doc = parse(u)\n",
    "# Извлечение и вывод нужных тегов\n",
    "for item in doc.iterfind('channel/item'):\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubDate')\n",
    "    link = item.findtext('link')\n",
    "    print(title)\n",
    "    print(date)\n",
    "    print(link)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что если вы хотите провести дополнительную обработку, вам нужно\n",
    "заменить инструкции print() на что-то более интересное."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В очень многих приложениях нужно работать с XML-данными.\n",
    "\n",
    "XML не только широко используется в качестве формата для обмена данными через интернет, это\n",
    "также распространенный формат хранения данных приложений (обработка текста, музыкальные библиотеки и т. п.). \n",
    "\n",
    "Следующее обсуждение подразумевает, что\n",
    "читатель уже знаком с основами XML.\n",
    "\n",
    "Во многих случаях, когда XML просто используется для хранения данных,\n",
    "структура документа проста и прямолинейна. \n",
    "\n",
    "Например, RSS-поток из примера\n",
    "выглядит примерно так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<?xml version=\"1.0\"?>\n",
    "<rss version=\"2.0\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\">\n",
    "<channel>\n",
    "    <title>Planet Python</title>\n",
    "    <link>http://planet.python.org/</link>\n",
    "    <language>en</language>\n",
    "    <description>Planet Python - http://planet.python.org/</description>\n",
    "    <item>\n",
    "        <title>Steve Holden: Python for Data Analysis</title>\n",
    "        <guid>http://holdenweb.blogspot.com/...-data-analysis.html</guid>\n",
    "        <link>http://holdenweb.blogspot.com/...-data-analysis.html</link>\n",
    "        <description>...</description>\n",
    "        <pubDate>Mon, 19 Nov 2012 02:13:51 +0000</pubDate>\n",
    "    </item>\n",
    "    <item>\n",
    "        <title>Vasudev Ram: The Python Data model (for v2 and v3)</title>\n",
    "        <guid>http://jugad2.blogspot.com/...-data-model.html</guid>\n",
    "        <link>http://jugad2.blogspot.com/...-data-model.html</link>\n",
    "        <description>...</description>\n",
    "        <pubDate>Sun, 18 Nov 2012 22:06:47 +0000</pubDate>\n",
    "    </item>\n",
    "    <item>\n",
    "        <title>Python Diary: Been playing around with Object Databases</title>\n",
    "        <guid>http://www.pythondiary.com/...-object-databases.html</guid>\n",
    "        <link>http://www.pythondiary.com/...-object-databases.html</link>\n",
    "        <description>...</description>\n",
    "        <pubDate>Sun, 18 Nov 2012 20:40:29 +0000</pubDate>\n",
    "    </item>\n",
    " ...\n",
    "</channel>\n",
    "</rss>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция xml.etree.ElementTree.parse() парсит весь XML-документ в объект document. Далее вы можете использовать такие методы, как find(), iterfind() и findtext(),\n",
    "для поиска определенных XML-элементов. \n",
    "\n",
    "Аргументы этих функций – это имена\n",
    "определенных тегов, такие как channel/item или title.\n",
    "Когда вы задаете теги, то должны принимать во внимание всю структуру документа. Каждая операция поиска предпринимается относительно стартового элемента. \n",
    "\n",
    "Тег, который вы предоставляете каждой операции, также рассматривается\n",
    "относительно старта. \n",
    "\n",
    "В  вышеприведенном примере вызов doc.iterfind('channel/\n",
    "item') найдет все элементы «item» под элементом «channel». doc представляет вершину документа (высший уровень – элемент «rss»). \n",
    "\n",
    "Последующие вызовы item.findtext() будут делаться относительно найденных элементов «item».\n",
    "Каждый элемент, представленный модулем ElementTree, имеет несколько основных атрибутов и методов, весьма полезных при парсинге. \n",
    "\n",
    "Атрибут tag содержит имя тега, атрибут text содержит прилагаемый текст, а метод get() может быть\n",
    "использован для извлечения атрибутов (если они присутствуют). \n",
    "\n",
    "Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.etree.ElementTree.ElementTree at 0x22d8c4a1358>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'title' at 0x0000022D8C4A7E58>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = doc.find('channel/title')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Planet Python'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get('some_attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить, что xml.etree.ElementTree – не единственный способ парсинга XML. Для более продвинутых приложений вы можете попробовать lxml. \n",
    "\n",
    "Эта\n",
    "библиотека использует тот же интерфейс, что и  ElementTree, так что вышеприведенные примеры будут работать так же. \n",
    "\n",
    "Вы просто должны изменить первую\n",
    "инструкцию import на from lxml.etree import parse. Библиотека lxml имеет преимущество – полное соответствие стандартам XML. Она также чрезвычайно быстро\n",
    "работает и предоставляет поддержку таких возможностей, как валидация, XSLT\n",
    "и XPath."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пошаговый парсинг очень больших XMl-файлов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам нужно извлечь данные из огромного XML документа, используя как можно меньше памяти. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый раз, когда вы сталкиваетесь с пошаговой обработкой данных, вы должны вспоминать об итераторах и генераторах. \n",
    "\n",
    "Вот простая функция, которая может быть использована для пошаговой обработки огромных XML файлов при очень небольшом потреблении памяти: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import iterparse \n",
    "\n",
    "def parse_and_remove(filename, path):\n",
    "    path_parts = path.split('/') \n",
    "    doc = iterparse(filename, ('start', 'end'))     \n",
    "    # Пропуск корневого элемента     \n",
    "    next(doc)\n",
    "    \n",
    "    tag_stack = []     \n",
    "    elem_stack = []     \n",
    "    for event, elem in doc:     \n",
    "        if event == 'start':\n",
    "            tag_stack.append(elem.tag) \n",
    "            elem_stack.append(elem) \n",
    "        elif event == 'end':\n",
    "            if tag_stack == path_parts:                 \n",
    "                yield elem \n",
    "                elem_stack[-2].remove(elem) \n",
    "            try:\n",
    "                tag_stack.pop() \n",
    "                elem_stack.pop()\n",
    "            except IndexError: \n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы протестировать функцию, вам потребуется большой XML файл. \n",
    "Часто такие файлы можно найти на государственных сайтах и ресурсах с открытой информацией. \n",
    "\n",
    "Например, вы можете скачать базу данных выбоин на дорогах Чикаго в формате XML. \n",
    "\n",
    "Когда писалась эта книга, данный файл состоял из более чем 100 000 строк данных, которые были закодированы так: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<response>     \n",
    "    <row>         \n",
    "        <row ...>\n",
    "            <creation_date>2012-11-18T00:00:00</creation_date>         \n",
    "            <status>Completed</status>\n",
    "            <completion_date>2012-11-18T00:00:00</completion_date>             \n",
    "            <service_request_number>12-01906549</service_request_number>\n",
    "            <type_of_service_request>Pot Hole in Street</type_of_service_request>\n",
    "            <current_activity>Final Outcome</current_activity>\n",
    "            <most_recent_action>CDOT Street Cut ... Outcome</most_recent_action>\n",
    "            <street_address>4714 S TALMAN AVE</street_address>\n",
    "            <zip>60632</zip>\n",
    "            <x_coordinate>1159494.68618856</x_coordinate>\n",
    "            <y_coordinate>1873313.83503384</y_coordinate>\n",
    "            <ward>14</ward>\n",
    "            <police_district>9</police_district>\n",
    "            <community_area>58</community_area>\n",
    "            <latitude>41.808090232127896</latitude>\n",
    "            <longitude>-87.69053684711305</longitude>\n",
    "            <location latitude=\"41.808090232127896\" longitude=\"-87.69053684711305\" />         \n",
    "        /row>\n",
    "        <row ...>\n",
    "            <creation_date>2012-11-18T00:00:00</creation_date>\n",
    "            <status>Completed</status>             \n",
    "            <completion_date>2012-11-18T00:00:00</completion_date>\n",
    "            <service_request_number>12-01906695</service_request_number>\n",
    "            <type_of_service_request>Pot Hole in Street</type_of_service_request>\n",
    "            <current_activity>Final Outcome</current_activity>\n",
    "            <most_recent_action>CDOT Street Cut ... Outcome</most_recent_action>\n",
    "            <street_address>3510 W NORTH AVE</street_address>\n",
    "            <zip>60647</zip>\n",
    "            <x_coordinate>1152732.14127696</x_coordinate>\n",
    "            <y_coordinate>1910409.38979075</y_coordinate>\n",
    "            <ward>26</ward>\n",
    "            <police_district>14</police_district>\n",
    "            <community_area>23</community_area>\n",
    "            <latitude>41.91002084292946</latitude>\n",
    "            <longitude>-87.71435952353961</longitude>\n",
    "            <location latitude=\"41.91002084292946\"  longitude=\"-87.71435952353961\" />\n",
    "        </row>\n",
    "    </row> \n",
    "</response> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что вы хотите написать скрипт, который отсортирует ZIP коды по количеству отчетов о выбоинах.\n",
    "\n",
    "Чтобы сделать это, вы можете написать такой код:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree \n",
    "import parse \n",
    "from collections \n",
    "import Counter \n",
    " \n",
    "potholes_by_zip = Counter() \n",
    " \n",
    "doc = parse('potholes.xml') \n",
    "for pothole in doc.iterfind('row/row'):     \n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1 \n",
    "for zipcode, num in potholes_by_zip.most_common():     \n",
    "    print(zipcode, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Единственная проблема с этим скриптом заключается в том, что он читает в память XML файл целиком. На нашем компьютере при запуске он отъел 450 мегабайт оперативной памяти. Если же применить код из этого рецепта, программа изменится совсем чуть-чуть:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections \n",
    "import Counter potholes_by_zip = Counter() \n",
    " \n",
    "data = parse_and_remove('potholes.xml', 'row/row') \n",
    "for pothole in data:     \n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1 \n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но эта версия занимает при запуске всего 7 мегабайт оперативной памяти – огромная экономия налицо!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот рецепт основывается на двух базовых возможностях модуля ElementTree. \n",
    "\n",
    "Метод iterparse() позволяет обрабатывать XML документы пошагово. \n",
    "\n",
    "Чтобы использовать его, вы передаете имя файла вместе со списком событий, состоящим из одного или более следующих аргументов: start, end, start-ns и end-ns.\n",
    "\n",
    "Итератор, созданный iterparse(), производит кортежи формата (event, elem), где event – одно из событий списка, а elem – полученный XML элемент. \n",
    "\n",
    "Например:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iterparse('potholes.xml',('start','end'))\n",
    "next(data) \n",
    "#('start', <Element 'response' at 0x100771d60>) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(data) \n",
    "#('start', <Element 'row' at 0x100771e68>) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(data) \n",
    "#('start', <Element 'row' at 0x100771fc8>) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "События start создаются, когда элемент создан, но еще не наполнен любыми другими данными (например, элементами потомками). \n",
    "\n",
    "События end создаются, когда элемент завершен. \n",
    "\n",
    "Хотя в данном рецепте это и не показано, события startns и end-ns используются для работы с объявлениями пространств имен XML. \n",
    "\n",
    "В этом рецепте события start и end используются для управления стеками элементов и тегов. \n",
    "\n",
    "Стеки представляют текущую иерархическую структуру документа в процессе его парсинга, а также используются для определения того, совпадает ли элемент с запрашиваемым путем, переданным в функцию parse_and_remove(). \n",
    "\n",
    "Если совпадение произошло, yield выдает его обратно вызывавшему. \n",
    "\n",
    "Следующая инструкция после yield – базовая возможность Element.Tree, которая позволяет этому рецепту экономить память: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem_stack[-2].remove(elem) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта инструкция удаляет выданный ранее элемент из его родителя. \n",
    "\n",
    "Исходя из предположения, что нигде более на него не осталось ссылок, элемент уничтожается, а память высвобождается. \n",
    "\n",
    "Конечный эффект итеративного парсинга и удаления узлов – крайне эффективный пошаговый проход по документу. \n",
    "\n",
    "Ни на одном этапе не создается полное дерево документа. \n",
    "\n",
    "Однако можно написать код, который обрабатывает XMLданные прямолинейным способом. \n",
    "\n",
    "Главный недостаток этого рецепта – производительность.\n",
    "\n",
    "При тестировании версия, которая читает весь документ в память, отработала в 2 раза быстрее, чем пошаговая.\n",
    "\n",
    "Однако она потребовала в 60 раз больше памяти. Так что если память важна, пошаговый подход дает большой выигрыш."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Преобразование словарей в XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы хотите взять данные из словаря Python и превратить их в XML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотя библиотека xml.etree.ElementTree обычно используется для парсинга, ее также можно применить для создания XML-документов. Например, посмотрите на\n",
    "такую функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_xml(tag, d):\n",
    "    '''Превращает простой словарь пар ключ/значение в XML'''\n",
    "    elem = Element(tag)\n",
    "    for key, val in d.items():\n",
    "        child = Element(key)\n",
    "        child.text = str(val)\n",
    "        elem.append(child)\n",
    "        return elem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот пример ее работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'stock' at 0x00000221D7FA14F8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = { 'name': 'GOOG', 'shares': 100, 'price':490.1 }\n",
    "e = dict_to_xml('stock', s)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результатом этого преобразования является экземпляр Element. \n",
    "\n",
    "Для ввода-вывода его можно легко конвертировать в байтовую строку – для этого нужно использовать функцию tostring() из модуля xml.etree.ElementTree. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<stock><name>GOOG</name></stock>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree.ElementTree import tostring\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите прикрепить атрибуты к элементу, используйте метод set():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<stock _id=\"1234\"><name>GOOG</name></stock>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.set('_id','1234')\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если порядок элементов имеет значение, подумайте над созданием OrderedDict вместо обычного словаря."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При генерации XML вы можете склоняться к  простому созданию строк. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_xml_str(tag, d):\n",
    "    '''Превращает простой словарь пар ключ/значение в XML'''\n",
    "    parts = ['<{}>'.format(tag)]\n",
    "    for key, val in d.items():\n",
    "        parts.append('<{0}>{1}</{0}>'.format(key,val))\n",
    "        parts.append('</{}>'.format(tag))\n",
    "        return ''.join(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема в  том, что вы влезете в  большие неприятности, если попытаетесь сделать это вручную. Например, что случится, если значения словаря будут содержать спецсимволы? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = { 'name' : '<spam>' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<item><name><spam></name></item>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание строки\n",
    "dict_to_xml_str('item', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<item><name>&lt;spam&gt;</name></item>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Правильное создание XML\n",
    "e = dict_to_xml('item',d)\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, как в последнем примере символы <and>заменяются на &lt;and&gt;.\n",
    "    \n",
    "Для справки: если вам когда-либо потребуется вручную экранировать или деэкранировать такие символы, вы можете использовать функции escape() и unescape()\n",
    "из модуля xml.sax.saxutils. Например:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&lt;spam&gt;'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.sax.saxutils import escape, unescape\n",
    "escape('<spam>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<spam>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unescape(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если оставить в стороне создание правильного вывода, другая причина создавать экземпляры Element вместо строк заключается в том, что их легче объединять\n",
    "друг с другом для создания более крупного документа. \n",
    "\n",
    "Получающиеся экземпляры Element также могут быть обработаны различными способами без необходимостипарсить XML-текст. \n",
    "\n",
    "Вы можете провести всю обработку данных высокоуровневым\n",
    "способом, а затем в самом конце вывести их в строковой форме."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Парсинг, изменение и перезапись XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы хотите прочесть XML-документ, изменить его, а затем записать обратно в форме XML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модуль xml.etree.ElementTree облегчает выполнение таких задач. Вы можете начать\n",
    "с парсинга документа обычным способом. Предположим, например, что у вас есть\n",
    "документ под названием pred.xml, который выглядит так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот пример того, как можно использовать ElementTree для прочтения документа и изменения его структуры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'stop' at 0x0000019699F35C78>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree.ElementTree import parse, Element\n",
    "doc = parse('pred.xml')\n",
    "root = doc.getroot()\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим несколько элементов\n",
    "root.remove(root.find('sri'))\n",
    "root.remove(root.find('cr'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Вставка нового элемента после <nm>...</nm>\n",
    "root.getchildren().index(root.find('nm'))\n",
    "e = Element('spam')\n",
    "e.text = 'This is a test'\n",
    "root.insert(2, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись обратно в файл\n",
    "doc.write('newpred.xml', xml_declaration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменение структуры XML-документа – незамысловатый процесс, но вы должны помнить, что все изменения в общем применяются к родительскому элементу, и они обращаются с ним как со списком. Например, если вы уберете элемент, он будет убран из его непосредственного родителя путем использования метода\n",
    "remove() родителя. \n",
    "\n",
    "Если вы вставляете или добавляете новые элементы в конец, вы также применяете методы insert() и append() к родителю. Еще можно манипулировать элементами с помощью операций индексирования и извлечения среза,\n",
    "таких как element[i] или element[j:j].\n",
    "\n",
    "Если вы хотите создать новые элементы, используйте класс Element, как показано в этом рецепте. Это также описано в рецепте 6.5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Парсинг XML-документов с пространствами имен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам нужно распарсить XML-документ, но он использует пространства имен XML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что у нас есть документ, использующий пространства имен:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D1%81%D1%82%D0%B2%D0%BE_%D0%B8%D0%BC%D1%91%D0%BD_(XML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы парсите этот документ и пытаетесь выполнить обычные запросы, вы обнаружите, что это не работает так просто, поскольку все становится невероятно\n",
    "многословным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import parse, Element\n",
    "doc = parse('beazley.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'David Beazley'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Некоторые запросы, которые работают\n",
    "doc.findtext('author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'content' at 0x000001B5A5E374F8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запрос с использованием пространства имен (не работает)\n",
    "doc.find('content/html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element '{http://www.w3.org/1999/xhtml}html' at 0x000001B5A81A2778>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Работает при полном определении\n",
    "doc.find('content/{http://www.w3.org/1999/xhtml}html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Не работает\n",
    "doc.findtext('content/{http://www.w3.org/1999/xhtml}html/head/title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Полностью определен\n",
    "doc.findtext('content/{http://www.w3.org/1999/xhtml}html/{http://www.w3.org/1999/xhtml}head/{http://www.w3.org/1999/xhtml}title')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто вы можете упростить дело путем заворачивания работы с пространством\n",
    "имен во вспомогательный класс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XMLNamespaces:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.namespaces = {}\n",
    "        for name, uri in kwargs.items():\n",
    "            self.register(name, uri)\n",
    "        print('kwargs = ', kwargs)\n",
    "        print('self.namespaces=', self.namespaces)\n",
    "            \n",
    "    def register(self, name, uri):\n",
    "        self.namespaces[name] = '{'+uri+'}'\n",
    "        \n",
    "    def __call__(self, path):\n",
    "        return path.format_map(self.namespaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pythonz.net/references/named/str.format_map/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/python-string-format_map/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы использовать этот класс, вы можете поступить так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs =  {'html': 'http://www.w3.org/1999/xhtml'}\n",
      "self.namespaces= {'html': '{http://www.w3.org/1999/xhtml}'}\n"
     ]
    }
   ],
   "source": [
    "ns = XMLNamespaces(html='http://www.w3.org/1999/xhtml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element '{http://www.w3.org/1999/xhtml}html' at 0x000001B5A81A2778>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find(ns('content/{html}html'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.findtext(ns('content/{html}html/{html}head/{html}title'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсинг XML-документов, содержащих пространства имен, может быть запутанным. \n",
    "\n",
    "Класс XMLNamespaces на самом деле предназначен для облегчения этой задачи: он позволяет использовать сокращенные имена для пространств имен в последующих операциях, а не полные URI.\n",
    "\n",
    "К несчастью, в базовом парсере ElementTree нет механизма для получения дополнительной информации о пространствах имен. \n",
    "\n",
    "Однако вы можете получить немного больше информации об области видимости обработки пространств имен, если будете использовать функцию iterparse(). Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end <Element 'author' at 0x000001B5A81BE0E8>\n",
      "start-ns ('', 'http://www.w3.org/1999/xhtml')\n",
      "end <Element '{http://www.w3.org/1999/xhtml}title' at 0x000001B5A81BE368>\n",
      "end <Element '{http://www.w3.org/1999/xhtml}head' at 0x000001B5A81BE318>\n",
      "end <Element '{http://www.w3.org/1999/xhtml}h1' at 0x000001B5A81BE408>\n",
      "end <Element '{http://www.w3.org/1999/xhtml}body' at 0x000001B5A81BE3B8>\n",
      "end <Element '{http://www.w3.org/1999/xhtml}html' at 0x000001B5A81BE2C8>\n",
      "end-ns None\n",
      "end <Element 'content' at 0x000001B5A81BE098>\n",
      "end <Element 'top' at 0x000001B5A81A8E58>\n"
     ]
    }
   ],
   "source": [
    "from xml.etree.ElementTree import iterparse\n",
    "for evt, elem in iterparse('beazley.xml', ('end', 'start-ns', 'end-ns')):\n",
    "    print(evt, elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'top' at 0x000001B5A81A8E58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Это самый верхний элемент\n",
    "elem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последнее замечание: если текст, который вы парсите, использует пространства имен в дополнение к другим продвинутым возможностям XML, вам лучше\n",
    "перейти с ElementTree на библиотеку lxml. \n",
    "\n",
    "Например, она предоставляет улучшенную поддержку валидации документов по DTD, более полную поддержку XPath\n",
    "и другие продвинутые возможности XML. \n",
    "\n",
    "А этот рецепт – просто небольшой фикс для облегчения парсинга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Взаимодействие с реляционной базой данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам нужно выбирать, вставлять или удалять строки в реляционной базе данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартный способ представления строк данных в Python – это последовательность кортежей. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = [\n",
    "    ('GOOG', 100, 490.1),\n",
    "    ('AAPL', 50, 545.75),\n",
    "    ('FB', 150, 7.45),\n",
    "    ('HPQ', 75, 33.2),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если данные представлены в такой форме, относительно легко наладить взаимодействие с реляционной базой данных, используя стандартный API баз данных\n",
    "Python, как описано в PEP 2491. \n",
    "\n",
    "Суть API в том, что все операции с базой данных\n",
    "выполняются с помощью SQL-запросов. \n",
    "\n",
    "Каждая строка вводимых или выводимых данных представлена в форме кортежа.\n",
    "\n",
    "Чтобы попробовать это в деле, вы можете воспользоваться модулем sqlite3, который входит в стандартную поставку Python. \n",
    "\n",
    "Если вы используете другую базу\n",
    "данных (например, MySQL, Postgres, ODBC), вы должны будете установить стороннюю библиотеку. \n",
    "\n",
    "Однако программный интерфейс будет практически таким же,\n",
    "если не идентичным.\n",
    "\n",
    "Первый шаг – подсоединиться к базе данных. \n",
    "\n",
    "Обычно для этого нужно вызвать функцию connect() и передать ей такие параметры, как имя базы данных, имя хоста, имя пользователя, пароль и другие детали, по мере необходимости. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db = sqlite3.connect('database.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы что-то делать с данными, нужно создать курсор. Когда у вас есть курсор,\n",
    "вы можете выполнять SQL-запросы. Например:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = db.cursor()\n",
    "c.execute('create table portfolio (symbol text, shares integer, price real)')\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы вставить последовательность строк в  данные, используйте такую инструкцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.executemany('insert into portfolio values (?,?,?)', stocks)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сделать запрос, используйте такую инструкцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GOOG', 100, 490.1)\n",
      "('AAPL', 50, 545.75)\n",
      "('FB', 150, 7.45)\n",
      "('HPQ', 75, 33.2)\n"
     ]
    }
   ],
   "source": [
    "for row in db.execute('select * from portfolio'):\n",
    "    print(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите сделать запросы, которые принимают поставляемые пользователем входные параметры, убедитесь, что вы экранируете параметры, используя\n",
    "символ ?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GOOG', 100, 490.1)\n",
      "('AAPL', 50, 545.75)\n"
     ]
    }
   ],
   "source": [
    "min_price = 100\n",
    "for row in db.execute('select * from portfolio where price >= ?', (min_price,)):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ru.wikipedia.org/wiki/%D0%92%D0%BD%D0%B5%D0%B4%D1%80%D0%B5%D0%BD%D0%B8%D0%B5_SQL-%D0%BA%D0%BE%D0%B4%D0%B0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На низком уровне взаимодействие с базой данных выполняется абсолютно прямолинейно. \n",
    "\n",
    "Вы просто формируете SQL-запросы и скармливаете их модулю, чтобы либо обновить информацию в базе, либо извлечь данные. \n",
    "\n",
    "Тем не менее есть тонкие моменты, с которыми в некоторых случаях придется разбираться.\n",
    "\n",
    "Одно из возможных осложнений – отображение данных из базы на типы Python.\n",
    "\n",
    "Для записей типа дат наиболее частым случаем будет использование экземпляров datetime из одноименного модуля или системных временных меток (timestamps)\n",
    "с применением модуля time. \n",
    "\n",
    "Для числовых данных, и особенно финансовых данных, в которых применяются десятичные дроби, может применяться представление чисел как экземпляров Decimal из модуля decimal. \n",
    "\n",
    "К сожалению, конкретные принципы отображения варьируются в зависимости от бэкэнда базы данных, так\n",
    "что вам придется почитать документацию.\n",
    "\n",
    "Еще одно критически важное осложнение касается формирования строк с инструкциями SQL. \n",
    "\n",
    "Вы никогда не должны использовать операторы форматирования строк Python (например, %) или метод .format() для создания таких строк. \n",
    "\n",
    "Если значения, предоставленные таким операторам форматирования, вводятся пользователями, это открывает вашу программу для SQL-инъекций \n",
    "(см. http://xkcd.com/3271). \n",
    "\n",
    "Специальный подменяющий символ ? в запросах требует от бэкэнда базы данных использовать его собственный механизм подстановки строк, который (будем надеяться) делает это безопасно.\n",
    "\n",
    "К сожалению, существует некоторое разнообразие в том, как бэкэнды различных баз данных интерпретируют символы подстановки. \n",
    "\n",
    "Многие модули используют ? или %s, тогда как другие могут использовать иной символ, такой как :0\n",
    "или :1, чтобы ссылаться на параметры. \n",
    "\n",
    "Вам нужно обратиться к документации используемого модуля базы данных. Атрибут paramstyle модуля базы данных также\n",
    "содержит информацию о стиле использования кавычек.\n",
    "\n",
    "Для простого взаимодействия с таблицей базы данных использовать API обычно очень просто. Если вы делаете что-то более нетривиальное, имеет смысл использовать высокоуровневый интерфейс, такой как объектно-реляционные отображатели (ORM). \n",
    "\n",
    "Библиотеки типа SQLAlchemy2 позволяют описывать таблицы базы данных как классы Python и выполнять операции с базами данных, скрывая весь лежащий в основе SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Декодирование и кодирование шестнадцатеричных цифр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам нужно декодировать строку шестнадцатеричных цифр в байтовую строку или закодировать байтовую строку в шестнадцатеричное представление."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вам просто нужно декодировать или закодировать сырую строку шестнадцатеричных цифр, используйте модуль binascii. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'68656c6c6f'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Изначальная байтовая строка\n",
    "s = b'hello'\n",
    "# Закодировать в hex\n",
    "import binascii\n",
    "h = binascii.b2a_hex(s)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Декодировать обратно в байты\n",
    "binascii.a2b_hex(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похожую функцию можно найти в модуле base64. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'68656C6C6F'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "h = base64.b16encode(s)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b16decode(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По большей части конвертирование в шестнадцатеричную форму и из шестнадцатеричной формы с помощью показанных приемов не составляет труда. \n",
    "\n",
    "Главная разница между этими двумя техниками заключается в  приведении к  регистру.\n",
    "\n",
    "Функции base64.b16decode() и base64.b16encode() работают только с шестнадцатеричными символами в верхнем регистре, а функции из модуля binascii могут работать с обоими регистрами.\n",
    "\n",
    "Также важно отметить, что вывод, который производят кодирующие функции, всегда является байтовой строкой. \n",
    "\n",
    "Чтобы принудительно вывести его в Unicode,\n",
    "вам придется добавить дополнительный шаг декодирования. Например:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'68656C6C6F'\n"
     ]
    }
   ],
   "source": [
    "h = base64.b16encode(s)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68656C6C6F\n"
     ]
    }
   ],
   "source": [
    "print(h.decode('ascii'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При декодировании шестнадцатеричных цифр функции b16decode() и a2b_hex() принимают и байтовые, и юникодовые строки. \n",
    "\n",
    "Однако эти строки должны содержать только закодированные в ASCII шестнадцатеричные цифры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Кодирование и декодирование в Base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам нужно декодировать или закодировать бинарные данные, используя кодировку Base64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'aGVsbG8='"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Какие-то байтовые данные\n",
    "s = b'hello'\n",
    "import base64\n",
    "# Закодировать в Base64\n",
    "a = base64.b64encode(s)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Декодировать из Base64\n",
    "base64.b64decode(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодировка Base64 предназначена только для использования с  байториентированными данными, такими как байтовые строки и байтовые массивы.\n",
    "\n",
    "Более того, вывод процесса кодирования всегда будет байтовой строкой. \n",
    "\n",
    "Если вы смешиваете данные в Base64 с текстом в Unicode, вам придется выполнить дополнительный шаг для декодирования. \n",
    "\n",
    "Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aGVsbG8='"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = base64.b64encode(s).decode('ascii')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При декодировании Base64 могут быть предоставлены и  байтовые строки, и текстовые строки в Unicode. \n",
    "\n",
    "Однако строки Unicode могут содержать только символы ASCII."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение и запись бинарных массивов структур"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы хотите прочесть или записать данные, закодированные как бинарный массив из единообразных структур, в кортежи Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы работать с  бинарными данными, используйте модуль struct. \n",
    "Вот пример кода, который записывает список кортежей Python в  бинарный файл, кодируя\n",
    "каждый кортеж в структуру с помощью модуля struct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import Struct\n",
    "\n",
    "def write_records(records, format, f):\n",
    "    '''Записывает последовательность кортежей в бинарный файл структур.'''\n",
    "    record_struct = Struct(format)\n",
    "    for r in records:\n",
    "        f.write(record_struct.pack(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [(1, 2.3, 4.5), (6, 7.8, 9.0), (12, 13.4, 56.7)]\n",
    "with open('data.b', 'wb') as f:\n",
    "    write_records(records, '<idd', f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть несколько подходов к обратному превращению этого файла в список кортежей. Во-первых, если вы читаете файл пошагово кусочками (chunks), то можете\n",
    "написать такой код:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import Struct\n",
    "def read_records(format, f):\n",
    "    record_struct = Struct(format)\n",
    "    chunks = iter(lambda: f.read(record_struct.size), b'')\n",
    "    print('chunks', chunks)\n",
    "    print('record_struct.size = ', record_struct.size)\n",
    "    #print('list(chunks) = ', list(chunks))\n",
    "    return (record_struct.unpack(chunk) for chunk in chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks <callable_iterator object at 0x00000189ACDE8B38>\n",
      "record_struct.size =  20\n",
      "rec =  (1, 2.3, 4.5)\n",
      "rec =  (6, 7.8, 9.0)\n",
      "rec =  (12, 13.4, 56.7)\n"
     ]
    }
   ],
   "source": [
    "with open('data.b','rb') as f:\n",
    "    for rec in read_records('<idd', f):\n",
    "        # Обработка записи\n",
    "        print('rec = ', rec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите прочесть файл целиком в байтовую строку за один проход и преобразовывать его кусочек за кусочком, вы можете сделать это так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import Struct\n",
    "\n",
    "def unpack_records(format, data):\n",
    "    record_struct = Struct(format)\n",
    "    return (record_struct.unpack_from(data, offset)\n",
    "            for offset in range(0, len(data), record_struct.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec =  (1, 2.3, 4.5)\n",
      "rec =  (6, 7.8, 9.0)\n",
      "rec =  (12, 13.4, 56.7)\n"
     ]
    }
   ],
   "source": [
    "with open('data.b', 'rb') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "for rec in unpack_records('<idd', data):\n",
    "    # Обработка записи\n",
    "    print('rec = ', rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обоих случаях результатом будет итерируемый объект, который производит кортежи, которые были сохранены в файле при его создании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обсуждение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В программах, которые должны кодировать и  декодировать бинарные данные, обычно используют модуль struct. \n",
    "\n",
    "Чтобы объявить новую структуру, просто создайте экземпляр Struct, как показано ниже:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import Struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32-битное целое число (little endian), два числа с плавающей точкой\n",
    "# двойной точности\n",
    "record_struct = Struct('<idd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структуры всегда определяются путем использования набора кодов структур, таких как i, d, f и т. д. (см. документацию Python). \n",
    "\n",
    "Эти коды соответствуют определенным бинарным типам данных, таким как 32-битные целые числа, 64-битные\n",
    "числа с плавающей точкой, 32-битные числа с плавающей точкой и т. д. \n",
    "\n",
    "Символ < в качестве первого символа определяет порядок следования байтов. В этом примере он задает порядок байт от младшего к  старшему (little endian). \n",
    "\n",
    "Замените символ на >, чтобы задать порядок байт от старшего к младшему (big endian), илина ! для сетевого порядка байтов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сетевые стеки и протоколы также должны определять свою последовательность байтов, иначе два узла сети с разным порядком байтов просто не смогут взаимодействовать. Это наиболее яркий пример влияния порядка байтов на программы. Все уровни протокола TCP/IP работают в режиме \"от старшего к младшему\". Любое 16-ти или 32-х битное значение внутри заголовков различных уровней (такое как IP-адрес, длина пакета, контрольная сумма) должны отсылаться и получаться так, чтобы старший байт был первым.\n",
    "\n",
    "Порядок байтов \"от старшего к младшему\", используемый в протоколе TCP/IP, иногда еще называют сетевым порядком байтов. Даже если компьютеры в сети используют порядок \"от младшего к старшему\", многобайтные целочисленные значения для передачи их по сети должны быть преобразованы в сетевой порядок байтов, а затем еще раз преобразованы назад в порядок \"от младшего к старшему\" на принимающем компьютере."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный экземпляр Struct имеет различные атрибуты и методы для манипулирования структурами этого типа. Атрибут size содержит размер структуры в байтах, что полезно для операций ввода-вывода. \n",
    "\n",
    "Методы pack() и unpack() используются для упаковки и распаковки данных. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from struct import Struct\n",
    "record_struct = Struct('<idd')\n",
    "record_struct.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_struct.pack(1, 2.0, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда вы можете увидеть, что операции pack() и  unpack() вызываются, как функции уровня модуля:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import struct\n",
    "struct.pack('<idd', 1, 2.0, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2.0, 3.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct.unpack('<idd', _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это работает, но менее элегантно, нежели создание единственного экземпляра Struct, особенно если одна и та же структура появляется во многих местах вашего кода. \n",
    "\n",
    "Путем создания экземпляра Struct форматирующий код определяется только единожды, и все полезные операции прекрасным образом сгруппированы вместе. \n",
    "\n",
    "Это точно увеличит легкость поддерживания вашего кода (ведь вам придется вносить изменения только в одном месте).\n",
    "\n",
    "Код для чтения бинарных структур использует несколько интересных и элегантных идиом программирования. \n",
    "\n",
    "В функции read_records() функция iter() используется для создания итератора, который возвращает кусочки (chunks) фиксированного размера (см. рецепт ранее). \n",
    "\n",
    "Этот итератор раз за разом вызывает переданный\n",
    "пользователем вызываемый объект (в данном случае lambda: f.read(record_struct.size)), пока он не вернет определенное значение (в данном случае b'' на чем итерации останавливаются. \n",
    "\n",
    "Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<callable_iterator at 0x22a5d0d0128>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('data.b', 'rb')\n",
    "chunks = iter(lambda: f.read(20), b'')\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x01\\x00\\x00\\x00ffffff\\x02@\\x00\\x00\\x00\\x00\\x00\\x00\\x12@'\n",
      "b'\\x06\\x00\\x00\\x00333333\\x1f@\\x00\\x00\\x00\\x00\\x00\\x00\"@'\n",
      "b'\\x0c\\x00\\x00\\x00\\xcd\\xcc\\xcc\\xcc\\xcc\\xcc*@\\x9a\\x99\\x99\\x99\\x99YL@'\n"
     ]
    }
   ],
   "source": [
    "for chk in chunks:\n",
    "    print(chk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смысл использования итератора в том, что он позволяет записям создаваться с помощью генератора (generator comprehension), как показано в примере. \n",
    "\n",
    "Если бы вы не использовали это решение, ваш код мог бы выглядеть так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_records(format, f):\n",
    "    record_struct = Struct(format)\n",
    "    while True:\n",
    "        chk = f.read(record_struct.size)\n",
    "        if chk == b'':\n",
    "            break\n",
    "        yield record_struct.unpack(chk)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В функции unpack_records() используется другой подход – метод unpack_from().\n",
    "\n",
    "Это полезный метод для извлечения бинарных данных из более крупного бинарного массива, потому что он делает это без создания временных объектов или копий в памяти. \n",
    "\n",
    "Вы просто передаете ему байтовую строку (или любой массив) вместе с байтовым сдвигом (offset), и он распакует поля прямо из этого места.\n",
    "\n",
    "Если вы использовали unpack() вместо unpack_from(), то можете захотеть изменить код, чтобы создать большое количество маленьких срезов и вычислений\n",
    "сдвига. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_records(format, data):\n",
    "    record_struct = Struct(format)\n",
    "    return (record_struct.unpack(data[offset:offset + record_struct.size])\n",
    " for offset in range(0, len(data), record_struct.size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дополнение к тому, что эта версия сложнее читается, она также требует намного больше работы, поскольку выполняет различные вычисления сдвига, копирует\n",
    "данные и создает объекты среза. \n",
    "\n",
    "Если вы будете распаковывать много структур\n",
    "из большой байтовой строки, которую уже прочитали, unpack_from() будет более элегантным решением.\n",
    "\n",
    "Распаковка записей – одна из областей, где могут найти применение объекты namedtuple из модуля collections. \n",
    "\n",
    "Они позволят вам установить имена атрибутов на\n",
    "возвращаемые кортежи. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.3 4.5\n",
      "6 7.8 9.0\n",
      "12 13.4 56.7\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "Record = namedtuple('Record', ['kind','x','y'])\n",
    "\n",
    "with open('data.b', 'rb') as f:\n",
    "    records = (Record(*r) for r in read_records('<idd', f))\n",
    "    for r in records:\n",
    "        print(r.kind, r.x, r.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы пишете программу, которой нужно работать с большим количеством бинарных данных, вам стоит использовать библиотеку типа numpy. \n",
    "\n",
    "Например, вместо чтения бинарного файла в  список кортежей вы можете прочесть его в структурированный массив:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( 1,  2.3,  4.5), ( 6,  7.8,  9. ), (12, 13.4, 56.7)],\n",
       "      dtype=[('f0', '<i4'), ('f1', '<f8'), ('f2', '<f8')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "f = open('data.b', 'rb')\n",
    "records = np.fromfile(f, dtype='<i,<d,<d')\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2.3, 4.5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 7.8, 9.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " records[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И последнее: если вы столкнулись с задачей чтения бинарных данных в какомто известном формате (например, форматах растровых или векторных изображений, HDF5 и т. д.), проверьте, нет ли в Python модуля для работы с ними. \n",
    "\n",
    "Не стоит изобретать велосипед, если можно обойтись без этого."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Чтение вложенных и различных по размеру бинарных структур"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам нужно прочесть сложные бинарные данные, которые содержат коллекцию вложенных записей и/или записей различного размера. \n",
    "\n",
    "Такие данные могут включать изображения, видео, векторные изображения и т. д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модуль struct может быть использован для декодирования и кодирования бинарных данных практически любой структуры.\n",
    "\n",
    "Чтобы проиллюстрировать работу с задачей этого рецепта, предположим, что у вас есть структура данных Python,\n",
    "представляющая точки, составляющие набор многоугольников:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "polys = [\n",
    " [ (1.0, 2.5), (3.5, 4.0), (2.5, 1.5) ],\n",
    " [ (7.0, 1.2), (5.1, 3.0), (0.5, 7.5), (0.8, 9.0) ],\n",
    " [ (3.4, 6.3), (1.2, 0.5), (4.6, 9.2) ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь предположим, что данные были закодированы в бинарный файл, который начинается следующим заголовком:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Byte        Type        Description\n",
    "0           int         File code (0x1234, little endian)\n",
    "4           double      Minimum x (little endian)\n",
    "12          double      Minimum y (little endian)\n",
    "20          double      Maximum x (little endian)\n",
    "28          double      Maximum y (little endian)\n",
    "36          int         Number of polygons (little endian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После заголовка идет набор многоугольников, каждый из которых закодирован\n",
    "так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Byte        Type          Description\n",
    "\n",
    "0           int           Record length including length (N bytes)\n",
    "\n",
    "4-N         Points        Pairs of (X,Y) coords as doubles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы записать этот файл, вы можете использовать такой код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_polys(filename, polys):\n",
    "    # Определяем ограничивающий параллелепипед\n",
    "    flattened = list(itertools.chain(*polys))\n",
    "    min_x = min(x for x, y in flattened)\n",
    "    max_x = max(x for x, y in flattened)\n",
    "    min_y = min(y for x, y in flattened)\n",
    "    max_y = max(y for x, y in flattened)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(struct.pack('<iddddi', 0x1234, \n",
    "                            min_x, min_y, \n",
    "                            max_x, max_y, \n",
    "                            len(polys)))\n",
    "        for poly in polys:\n",
    "            size = len(poly) * struct.calcsize('<dd')\n",
    "            f.write(struct.pack('<i', size+4))\n",
    "            for pt in poly:\n",
    "                f.write(struct.pack('<dd', *pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вызываем с нашими данными полигонов\n",
    "write_polys('polys.bin', polys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы прочесть получившиеся данные обратно, вы можете написать похожий\n",
    "код с использованием функции struct.unpack(), которая обращает операции, проделанные во время записи. Например:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "def read_polys(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Читаем заголовок\n",
    "        header = f.read(40)\n",
    "        file_code, min_x, min_y, max_x, max_y, num_polys = struct.unpack('<iddddi', header)\n",
    "        polys = []\n",
    "        for n in range(num_polys):\n",
    "            pbytes = struct.unpack('<i', f.read(4))\n",
    "            poly = []\n",
    "            for m in range(pbytes // 16):\n",
    "                pt = struct.unpack('<dd', f.read(16))\n",
    "                poly.append(pt)\n",
    "            polys.append(poly)\n",
    "    return polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(1.0, 2.5), (3.5, 4.0), (2.5, 1.5)], [(7.0, 1.2), (5.1, 3.0), (0.5, 7.5), (0.8, 9.0)], [(3.4, 6.3), (1.2, 0.5), (4.6, 9.2)]]\n"
     ]
    }
   ],
   "source": [
    "new_polys = read_polys('polys.bin')\n",
    "print(new_polys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотя этот код работает, он представляет собой довольно-таки беспорядочный\n",
    "набор небольших операций чтения, распаковки структур и прочие детали. \n",
    "\n",
    "Если такой код используется для обработки реального файла с данными, он быстро станет еще более запутанным. \n",
    "\n",
    "Это делает очевидным необходимость поиска альтернативного решения, которое могло бы упростить некоторые шаги и позволило бы программисту сосредоточиться на более важных вещах.\n",
    "\n",
    "В оставшейся части этого рецепта мы шаг за шагом построим достаточно продвинутое решение для интерпретации бинарных данных. \n",
    "\n",
    "Наша цель  – предоставить программисту возможность передать высокоуровневую спецификацию формата файла, а все детали чтения и распаковки данных переместить в «подкапотную» часть. \n",
    "\n",
    "Заранее предупреждаем, что нижеследующий код будет самым\n",
    "продвинутым примером во всей книге. \n",
    "\n",
    "Он использует различные приемы объектно-ориентированного программирования и  метапрограммирования. \n",
    "\n",
    "Рекомендуем вам внимательно прочитать раздел «Обсуждение», обращая внимание на\n",
    "ссылки на другие рецепты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во-первых, при чтении бинарных данных наиболее типичный случай  – это присутствие в файле заголовков и других структур данных. \n",
    "\n",
    "Хотя модуль struct может распаковать эти данные в кортеж, еще один способ представить такую информацию – это использование класса. \n",
    "\n",
    "Вот пример кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "class StructField:\n",
    "    '''Дескриптор, представляющий простое поле структуры'''\n",
    "    def __init__(self, format, offset):\n",
    "        self.format = format\n",
    "        self.offset = offset\n",
    "    def __get__(self, instance, cls):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        else:\n",
    "            r = struct.unpack_from(self.format, instance._buffer, self.offset)\n",
    "            return r[0] if len(r) == 1 else r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Structure:\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = memoryview(bytedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот код использует дескриптор для представления каждого поля структуры.\n",
    "\n",
    "Каждый дескриптор содержит совместимый со struct формат кода вместе с байтовым сдвигом используемого буфера памяти. \n",
    "\n",
    "В методе __get__() функция struct.\n",
    "\n",
    "unpack_from() используется для распаковки значения из буфера без необходимости делать дополнительные срезы или копии.\n",
    "\n",
    "Класс Structure просто служит базовым классом (суперклассом), который принимает некие байтовые данные и сохраняет их в буфере памяти, используемом\n",
    "дескриптором StructField. \n",
    "\n",
    "Функция memoryview() в этом классе служит целям, которые мы проясним позднее.\n",
    "\n",
    "Этот код позволит вам определить структуру как высокоуровневый класс, который отражает информацию, найденную в таблицах, которые описывают ожидаемый формат файла. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyHeader(Structure):\n",
    "    file_code = StructField('<i', 0)\n",
    "    min_x = StructField('<d', 4)\n",
    "    min_y = StructField('<d', 12)\n",
    "    max_x = StructField('<d', 20)\n",
    "    max_y = StructField('<d', 28)\n",
    "    num_polys = StructField('<i', 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот пример использования этого класса для чтения заголовка из данных о многоугольниках, которые мы записали ранее:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('polys.bin', 'rb')\n",
    "phead = PolyHeader(f.read(40))\n",
    "phead.file_code == 0x1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.min_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " phead.min_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.max_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.max_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.num_polys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это интересно, но данный подход имеет несколько раздражающих нюансов.\n",
    "\n",
    "Даже если вы получаете удобство классоподобного интерфейса, код все равно\n",
    "многословен и требует от пользователя определять множество низкоуровневых\n",
    "деталей (например, повторяющееся использование StructField, определение сдвигов и т. п.). \n",
    "\n",
    "В получившемся классе также отсутствуют привычные удобные моменты, такие как предоставление способа вычислить общий размер структуры.\n",
    "\n",
    "Каждый раз, когда вы сталкиваетесь с подобным излишне многословным определением класса, вы можете подумать об использовании декоратора класса или\n",
    "метакласса. \n",
    "\n",
    "Одна из возможностей метакласса в том, что он может быть использован для выполнения множества низкоуровневых деталей реализации, снимая это\n",
    "бремя с пользователя. \n",
    "\n",
    "В качестве примера рассмотрите этот метакласс и слегка\n",
    "переработанный класс Structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureMeta(type):\n",
    "    '''Метакласс, который автоматически создает дескрипторы StructField'''\n",
    "    def __init__(self, clsname, bases, clsdict):\n",
    "        fields = getattr(self, '_fields_', [])\n",
    "        byte_order = ''\n",
    "        offset = 0\n",
    "        for format, fieldname in fields:\n",
    "            if format.startswith(('<','>','!','@')):\n",
    "                byte_order = format[0]\n",
    "                format = format[1:]\n",
    "            format = byte_order + format\n",
    "            setattr(self, fieldname, StructField(format, offset))\n",
    "            offset += struct.calcsize(format)\n",
    "        setattr(self, 'struct_size', offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Structure(metaclass=StructureMeta):\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = bytedata\n",
    "    @classmethod\n",
    "    def from_file(cls, f):\n",
    "        return cls(f.read(cls.struct_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя этот новый класс Structure, вы можете записывать определение\n",
    "структуры так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyHeader(Structure):\n",
    "    _fields_ = [\n",
    "        ('<i', 'file_code'),\n",
    "        ('d', 'min_x'),\n",
    "        ('d', 'min_y'),\n",
    "        ('d', 'max_x'),\n",
    "        ('d', 'max_y'),\n",
    "        ('i', 'num_polys')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы можете видеть, это определение намного компактнее. Добавленный метод класса from_file() также делает более удобным чтение данных из файла, снимая\n",
    "необходимость знать какие-либо детали о размере или структуре данных. Например:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('polys.bin', 'rb')\n",
    "phead = PolyHeader.from_file(f)\n",
    "phead.file_code == 0x1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " phead.min_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.min_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.max_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.num_polys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда вы вводите в программу метакласс, то можете встроить в него больше «интеллекта». \n",
    "\n",
    "Например, предположим, что вы хотите обеспечить поддержку вложенных бинарных структур. \n",
    "\n",
    "Вот переделанный метакласс вместе с новым дескриптором, который это поддерживает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedStruct:\n",
    "    '''Дескриптор, представляющий вложенную структуру'''\n",
    "    def __init__(self, name, struct_type, offset):\n",
    "        self.name = name\n",
    "        self.struct_type = struct_type\n",
    "        self.offset = offset\n",
    "        \n",
    "    def __get__(self, instance, cls):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        else:\n",
    "            data = instance._buffer[self.offset:self.offset+self.struct_type.struct_size]\n",
    "            result = self.struct_type(data)\n",
    "            # Сохраняем получившуюся структуру обратно в экземпляр,\n",
    "            # чтобы избежать последующего вычисления этого шага\n",
    "            setattr(instance, self.name, result)\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureMeta(type):\n",
    "    '''Метакласс, который автоматически создает дескрипторы StructField'''\n",
    "    def __init__(self, clsname, bases, clsdict):\n",
    "        fields = getattr(self, '_fields_', [])\n",
    "        byte_order = ''\n",
    "        offset = 0\n",
    "        for format, fieldname in fields:\n",
    "            if isinstance(format, StructureMeta):\n",
    "                setattr(self, fieldname,NestedStruct(fieldname, format, offset))\n",
    "                offset += format.struct_size\n",
    "            else:\n",
    "                print(format)\n",
    "                if format.startswith(('<','>','!','@')):\n",
    "                    byte_order = format[0]\n",
    "                    format = format[1:]\n",
    "                format = byte_order + format\n",
    "                setattr(self, fieldname, StructField(format, offset))\n",
    "                offset += struct.calcsize(format)\n",
    "        setattr(self, 'struct_size', offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Structure(metaclass=StructureMeta):\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = bytedata\n",
    "    @classmethod\n",
    "    def from_file(cls, f):\n",
    "        return cls(f.read(cls.struct_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом примере кода дескриптор NestedStruct используется для наложения другого определения структуры на область памяти. \n",
    "\n",
    "Он делает это путем извлечения среза изначального буфера памяти и использования его для создания экземпляра переданного типа структуры. \n",
    "\n",
    "Поскольку буфер памяти был инициализирован как memoryview, это извлечение среза не приводит к созданию дополнительных копий\n",
    "в памяти. \n",
    "\n",
    "Вместо этого оно накладывается на изначальную память. \n",
    "\n",
    "Более того, чтобы избежать повторения создания экземпляров, дескриптор сохраняет получившуюся внутреннюю структуру объекта в экземпляр, используя тот же прием,\n",
    "что мы описали в рецепте 8.10.\n",
    "\n",
    "Используя эту новую формулировку, вы можете начать писать код так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<d\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "class Point(Structure):\n",
    "    _fields_ = [\n",
    "        ('<d', 'x'),\n",
    "        ('d', 'y')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<i\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "class PolyHeader(Structure):\n",
    "    _fields_ = [\n",
    "        ('<i', 'file_code'),\n",
    "        (Point, 'min'),\n",
    "        (Point, 'max'),\n",
    "        ('i', 'num_polys')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удивительно, но код все еще работает так, как вы ожидаете. Например:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('polys.bin', 'rb')\n",
    "phead = PolyHeader.from_file(f)\n",
    "phead.file_code == 0x1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Point at 0x2049f95f358>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " phead.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.min.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.min.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.max.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.max.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.num_polys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом этапе мы разработали фреймворк для работы с записями фиксированного размера, но что делать с компонентами различных размеров? \n",
    "\n",
    "Например, оставшаяся часть файла с многоугольниками содержит элементы различных размеров.\n",
    "\n",
    "Первый путь – написать класс, который просто представляет кусок (chunk) бинарных данных вместе с вспомогательной функцией для интерпретирования содержимого различными способами. \n",
    "\n",
    "Это тесно связано с  подходом, описанным\n",
    "в рецепте 6.11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizedRecord:\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = memoryview(bytedata)\n",
    "        \n",
    "    @classmethod\n",
    "    def from_file(cls, f, size_fmt, includes_size=True):\n",
    "        sz_nbytes = struct.calcsize(size_fmt)\n",
    "        sz_bytes = f.read(sz_nbytes)\n",
    "        sz, = struct.unpack(size_fmt, sz_bytes)\n",
    "        buf = f.read(sz - includes_size * sz_nbytes)\n",
    "        return cls(buf)\n",
    "\n",
    "    def iter_as(self, code):\n",
    "        if isinstance(code, str):\n",
    "            s = struct.Struct(code)\n",
    "            for off in range(0, len(self._buffer), s.size):\n",
    "                yield s.unpack_from(self._buffer, off)\n",
    "        elif isinstance(code, StructureMeta):\n",
    "            size = code.struct_size\n",
    "            for off in range(0, len(self._buffer), size):\n",
    "                data = self._buffer[off:off+size]\n",
    "                yield code(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод класса SizedRecord.from_file() используется для чтения из файла куска (chunk) данных с префиксом, определяющим размер, что является обычным для многих форматов файлов. \n",
    "\n",
    "На вход он принимает код форматирования структуры,\n",
    "который содержит кодировку размера, который должен быть представлен в байтах. \n",
    "\n",
    "Необязательный аргумент includes_size определяет, включает число байтов заголовок размера или нет. \n",
    "\n",
    "Вот пример того, как вы можете использовать этот код\n",
    "для прочтения отдельного многоугольника из файла с многоугольниками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('polys.bin', 'rb')\n",
    "phead = PolyHeader.from_file(f)\n",
    "phead.num_polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.SizedRecord at 0x1bba40b3cf8>,\n",
       " <__main__.SizedRecord at 0x1bba40b3ef0>,\n",
       " <__main__.SizedRecord at 0x1bba40b3a20>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polydata = [SizedRecord.from_file(f, '<i') for n in range(phead.num_polys)]\n",
    "polydata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как показано выше, содержимое экземпляров SizeRecord пока еще не интерпретировано. \n",
    "\n",
    "Чтобы сделать это, используйте метод iter_as(), который принимает на вход код структуры формата или класс Structure. \n",
    "\n",
    "Это предоставляет вам немалую\n",
    "гибкость в том, как можно интерпретировать данные. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polygon 0\n",
      "(1.0, 2.5)\n",
      "(3.5, 4.0)\n",
      "(2.5, 1.5)\n",
      "Polygon 1\n",
      "(7.0, 1.2)\n",
      "(5.1, 3.0)\n",
      "(0.5, 7.5)\n",
      "(0.8, 9.0)\n",
      "Polygon 2\n",
      "(3.4, 6.3)\n",
      "(1.2, 0.5)\n",
      "(4.6, 9.2)\n"
     ]
    }
   ],
   "source": [
    "for n, poly in enumerate(polydata):\n",
    "    print('Polygon', n)\n",
    "    for p in poly.iter_as('<dd'):\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polygon 0\n",
      "1.0 2.5\n",
      "3.5 4.0\n",
      "2.5 1.5\n",
      "Polygon 1\n",
      "7.0 1.2\n",
      "5.1 3.0\n",
      "0.5 7.5\n",
      "0.8 9.0\n",
      "Polygon 2\n",
      "3.4 6.3\n",
      "1.2 0.5\n",
      "4.6 9.2\n"
     ]
    }
   ],
   "source": [
    "for n, poly in enumerate(polydata):\n",
    "    print('Polygon', n)\n",
    "    for p in poly.iter_as(Point):\n",
    "        print(p.x, p.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собирая все вместе, представим альтернативную реализацию функции read_\n",
    "polys():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<d\n",
      "d\n",
      "<i\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "class Point(Structure):\n",
    "    _fields_ = [\n",
    "        ('<d', 'x'),\n",
    "        ('d', 'y')\n",
    "    ]\n",
    "    \n",
    "class PolyHeader(Structure):\n",
    "    _fields_ = [\n",
    "        ('<i', 'file_code'),\n",
    "        (Point, 'min'),\n",
    "        (Point, 'max'),\n",
    "        ('i', 'num_polys')\n",
    "    ]\n",
    "    \n",
    "    \n",
    "def read_polys(filename):\n",
    "    polys = []\n",
    "    with open(filename, 'rb') as f:\n",
    "        phead = PolyHeader.from_file(f)\n",
    "        for n in range(phead.num_polys):\n",
    "            rec = SizedRecord.from_file(f, '<i')\n",
    "            poly = [(p.x, p.y) for p in rec.iter_as(Point)]\n",
    "            polys.append(poly)\n",
    "    return polys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Суммирование данных и обсчет статистики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам нужно обработать большие наборы данных и  сгенерировать суммы или какую-то другую статистику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для любого анализа данных с  использованием статистики, временных рядов и прочих подобных приемов вам стоит обратиться к библиотеке Pandas.\n",
    "\n",
    "Вот пример использования Pandas для анализа городской базы крыс и грызунов Чикаго. \n",
    "\n",
    "К моменту написания данной книги этот CSV-файл содержал около 74 000 записей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creation Date</th>\n",
       "      <th>Status</th>\n",
       "      <th>Completion Date</th>\n",
       "      <th>Service Request Number</th>\n",
       "      <th>Type of Service Request</th>\n",
       "      <th>Number of Premises Baited</th>\n",
       "      <th>Number of Premises with Garbage</th>\n",
       "      <th>Number of Premises with Rats</th>\n",
       "      <th>Current Activity</th>\n",
       "      <th>Most Recent Action</th>\n",
       "      <th>Street Address</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>X Coordinate</th>\n",
       "      <th>Y Coordinate</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Police District</th>\n",
       "      <th>Community Area</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07/31/2017</td>\n",
       "      <td>Completed</td>\n",
       "      <td>08/04/2017</td>\n",
       "      <td>17-05075019</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dispatch Crew</td>\n",
       "      <td>Area inspected, no cause and no baiting</td>\n",
       "      <td>1254 W BARRY AVE</td>\n",
       "      <td>60657.0</td>\n",
       "      <td>1.167392e+06</td>\n",
       "      <td>1.920715e+06</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.937997</td>\n",
       "      <td>-87.660207</td>\n",
       "      <td>(41.937997161449, -87.660206674922)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07/31/2017</td>\n",
       "      <td>Completed</td>\n",
       "      <td>08/04/2017</td>\n",
       "      <td>17-05081136</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dispatch Crew</td>\n",
       "      <td>Area inspected, no cause and no baiting</td>\n",
       "      <td>2742 N JANSSEN AVE</td>\n",
       "      <td>60614.0</td>\n",
       "      <td>1.166174e+06</td>\n",
       "      <td>1.918418e+06</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.931721</td>\n",
       "      <td>-87.664749</td>\n",
       "      <td>(41.931721198293, -87.664749441253)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/03/2017</td>\n",
       "      <td>Completed</td>\n",
       "      <td>08/04/2017</td>\n",
       "      <td>17-05150281</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dispatch Crew</td>\n",
       "      <td>Inspected and baited</td>\n",
       "      <td>311 W SCOTT ST</td>\n",
       "      <td>60610.0</td>\n",
       "      <td>1.173823e+06</td>\n",
       "      <td>1.908709e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.904911</td>\n",
       "      <td>-87.636932</td>\n",
       "      <td>(41.904910918355, -87.636931976355)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/01/2017</td>\n",
       "      <td>Completed</td>\n",
       "      <td>08/04/2017</td>\n",
       "      <td>17-05094467</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Dispatch Crew</td>\n",
       "      <td>Inspected and baited</td>\n",
       "      <td>2451 W CARMEN AVE</td>\n",
       "      <td>60625.0</td>\n",
       "      <td>1.159023e+06</td>\n",
       "      <td>1.933797e+06</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.974071</td>\n",
       "      <td>-87.690604</td>\n",
       "      <td>(41.974070947222, -87.690603571631)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/02/2017</td>\n",
       "      <td>Completed</td>\n",
       "      <td>08/04/2017</td>\n",
       "      <td>17-05124800</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Dispatch Crew</td>\n",
       "      <td>Inspected and baited</td>\n",
       "      <td>1762 W CULLOM AVE</td>\n",
       "      <td>60613.0</td>\n",
       "      <td>1.163875e+06</td>\n",
       "      <td>1.928604e+06</td>\n",
       "      <td>47.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.959719</td>\n",
       "      <td>-87.672909</td>\n",
       "      <td>(41.959719068016, -87.672908698842)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>07/31/2017</td>\n",
       "      <td>Completed</td>\n",
       "      <td>08/04/2017</td>\n",
       "      <td>17-05074211</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Dispatch Crew</td>\n",
       "      <td>Inspected and baited</td>\n",
       "      <td>6141 S RHODES AVE</td>\n",
       "      <td>60637.0</td>\n",
       "      <td>1.180962e+06</td>\n",
       "      <td>1.864411e+06</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.783193</td>\n",
       "      <td>-87.612073</td>\n",
       "      <td>(41.783193388759, -87.612072911265)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07/31/2017</td>\n",
       "      <td>Completed</td>\n",
       "      <td>08/04/2017</td>\n",
       "      <td>17-05079307</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Dispatch Crew</td>\n",
       "      <td>Inspected and baited</td>\n",
       "      <td>1254 W 102ND PL</td>\n",
       "      <td>60643.0</td>\n",
       "      <td>1.169572e+06</td>\n",
       "      <td>1.836966e+06</td>\n",
       "      <td>34.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>41.708135</td>\n",
       "      <td>-87.654629</td>\n",
       "      <td>(41.708135321794, -87.654628985942)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08/02/2017</td>\n",
       "      <td>Completed - Dup</td>\n",
       "      <td>08/04/2017</td>\n",
       "      <td>17-05124399</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4105 N PAULINA ST</td>\n",
       "      <td>60613.0</td>\n",
       "      <td>1.164492e+06</td>\n",
       "      <td>1.927328e+06</td>\n",
       "      <td>47.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.956204</td>\n",
       "      <td>-87.670677</td>\n",
       "      <td>(41.956204244754, -87.670677330448)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>07/31/2017</td>\n",
       "      <td>Completed</td>\n",
       "      <td>08/04/2017</td>\n",
       "      <td>17-05086039</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Dispatch Crew</td>\n",
       "      <td>Inspected and baited</td>\n",
       "      <td>1236 W 31ST PL</td>\n",
       "      <td>60608.0</td>\n",
       "      <td>1.168589e+06</td>\n",
       "      <td>1.883917e+06</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>41.836995</td>\n",
       "      <td>-87.656874</td>\n",
       "      <td>(41.836994528844, -87.65687408527)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08/02/2017</td>\n",
       "      <td>Completed</td>\n",
       "      <td>08/04/2017</td>\n",
       "      <td>17-05122361</td>\n",
       "      <td>Rodent Baiting/Rat Complaint</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Dispatch Crew</td>\n",
       "      <td>Inspected and baited</td>\n",
       "      <td>1526 W WOLFRAM ST</td>\n",
       "      <td>60657.0</td>\n",
       "      <td>1.165652e+06</td>\n",
       "      <td>1.919004e+06</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.933339</td>\n",
       "      <td>-87.666651</td>\n",
       "      <td>(41.93333873992, -87.666651223676)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Creation Date           Status Completion Date Service Request Number  \\\n",
       "0    07/31/2017        Completed      08/04/2017            17-05075019   \n",
       "1    07/31/2017        Completed      08/04/2017            17-05081136   \n",
       "2    08/03/2017        Completed      08/04/2017            17-05150281   \n",
       "3    08/01/2017        Completed      08/04/2017            17-05094467   \n",
       "4    08/02/2017        Completed      08/04/2017            17-05124800   \n",
       "5    07/31/2017        Completed      08/04/2017            17-05074211   \n",
       "6    07/31/2017        Completed      08/04/2017            17-05079307   \n",
       "7    08/02/2017  Completed - Dup      08/04/2017            17-05124399   \n",
       "8    07/31/2017        Completed      08/04/2017            17-05086039   \n",
       "9    08/02/2017        Completed      08/04/2017            17-05122361   \n",
       "\n",
       "        Type of Service Request  Number of Premises Baited  \\\n",
       "0  Rodent Baiting/Rat Complaint                        0.0   \n",
       "1  Rodent Baiting/Rat Complaint                        0.0   \n",
       "2  Rodent Baiting/Rat Complaint                        0.0   \n",
       "3  Rodent Baiting/Rat Complaint                        5.0   \n",
       "4  Rodent Baiting/Rat Complaint                        3.0   \n",
       "5  Rodent Baiting/Rat Complaint                        3.0   \n",
       "6  Rodent Baiting/Rat Complaint                        3.0   \n",
       "7  Rodent Baiting/Rat Complaint                        NaN   \n",
       "8  Rodent Baiting/Rat Complaint                        3.0   \n",
       "9  Rodent Baiting/Rat Complaint                        1.0   \n",
       "\n",
       "   Number of Premises with Garbage  Number of Premises with Rats  \\\n",
       "0                              0.0                           0.0   \n",
       "1                              1.0                           0.0   \n",
       "2                              0.0                           0.0   \n",
       "3                              4.0                           5.0   \n",
       "4                              1.0                           3.0   \n",
       "5                              4.0                           3.0   \n",
       "6                              2.0                           2.0   \n",
       "7                              NaN                           NaN   \n",
       "8                              0.0                           3.0   \n",
       "9                              3.0                           2.0   \n",
       "\n",
       "  Current Activity                       Most Recent Action  \\\n",
       "0    Dispatch Crew  Area inspected, no cause and no baiting   \n",
       "1    Dispatch Crew  Area inspected, no cause and no baiting   \n",
       "2    Dispatch Crew                     Inspected and baited   \n",
       "3    Dispatch Crew                     Inspected and baited   \n",
       "4    Dispatch Crew                     Inspected and baited   \n",
       "5    Dispatch Crew                     Inspected and baited   \n",
       "6    Dispatch Crew                     Inspected and baited   \n",
       "7              NaN                                      NaN   \n",
       "8    Dispatch Crew                     Inspected and baited   \n",
       "9    Dispatch Crew                     Inspected and baited   \n",
       "\n",
       "       Street Address  ZIP Code  X Coordinate  Y Coordinate  Ward  \\\n",
       "0    1254 W BARRY AVE   60657.0  1.167392e+06  1.920715e+06  32.0   \n",
       "1  2742 N JANSSEN AVE   60614.0  1.166174e+06  1.918418e+06  32.0   \n",
       "2      311 W SCOTT ST   60610.0  1.173823e+06  1.908709e+06   2.0   \n",
       "3   2451 W CARMEN AVE   60625.0  1.159023e+06  1.933797e+06  40.0   \n",
       "4   1762 W CULLOM AVE   60613.0  1.163875e+06  1.928604e+06  47.0   \n",
       "5   6141 S RHODES AVE   60637.0  1.180962e+06  1.864411e+06  20.0   \n",
       "6     1254 W 102ND PL   60643.0  1.169572e+06  1.836966e+06  34.0   \n",
       "7   4105 N PAULINA ST   60613.0  1.164492e+06  1.927328e+06  47.0   \n",
       "8      1236 W 31ST PL   60608.0  1.168589e+06  1.883917e+06  11.0   \n",
       "9   1526 W WOLFRAM ST   60657.0  1.165652e+06  1.919004e+06  32.0   \n",
       "\n",
       "   Police District  Community Area   Latitude  Longitude  \\\n",
       "0             19.0             6.0  41.937997 -87.660207   \n",
       "1             19.0             7.0  41.931721 -87.664749   \n",
       "2             18.0             8.0  41.904911 -87.636932   \n",
       "3             20.0             4.0  41.974071 -87.690604   \n",
       "4             19.0             6.0  41.959719 -87.672909   \n",
       "5              3.0            42.0  41.783193 -87.612073   \n",
       "6             22.0            73.0  41.708135 -87.654629   \n",
       "7             19.0             6.0  41.956204 -87.670677   \n",
       "8              9.0            60.0  41.836995 -87.656874   \n",
       "9             19.0             6.0  41.933339 -87.666651   \n",
       "\n",
       "                              Location  \n",
       "0  (41.937997161449, -87.660206674922)  \n",
       "1  (41.931721198293, -87.664749441253)  \n",
       "2  (41.904910918355, -87.636931976355)  \n",
       "3  (41.974070947222, -87.690603571631)  \n",
       "4  (41.959719068016, -87.672908698842)  \n",
       "5  (41.783193388759, -87.612072911265)  \n",
       "6  (41.708135321794, -87.654628985942)  \n",
       "7  (41.956204244754, -87.670677330448)  \n",
       "8   (41.836994528844, -87.65687408527)  \n",
       "9   (41.93333873992, -87.666651223676)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "# Прочесть CSV-файл, пропустив последнюю строку\n",
    "rats = pandas.read_csv('rats.csv', skipfooter=1)\n",
    "rats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dispatch Crew', nan, 'Request Sanitation Inspector',\n",
       "       'FVI - Outcome', 'Inspect for Violation'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Исследовать диапазон значений для определенного поля\n",
    "rats['Current Activity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297375"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Отфильровать данные\n",
    "crew_dispatched = rats[rats['Current Activity'] == 'Dispatch Crew']\n",
    "len(crew_dispatched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60618.0    17023\n",
       "60647.0    16153\n",
       "60629.0    12497\n",
       "60614.0    12061\n",
       "60657.0    10608\n",
       "60641.0     9803\n",
       "60636.0     9105\n",
       "60623.0     8896\n",
       "60609.0     8760\n",
       "60645.0     8673\n",
       "Name: ZIP Code, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Найти 10 самых сильно зараженных крысами ZIP-кодов (районов) в Чикаго\n",
    "crew_dispatched['ZIP Code'].value_counts().iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Группируем по дате завершения\n",
    "dates = crew_dispatched.groupby('Completion Date')\n",
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion Date\n",
       "01/01/2014      7\n",
       "01/02/2013     20\n",
       "01/02/2014     96\n",
       "01/02/2015      5\n",
       "01/02/2018     71\n",
       "01/03/2011      4\n",
       "01/03/2012    125\n",
       "01/03/2013     46\n",
       "01/03/2014     59\n",
       "01/03/2017    212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определяем ежедневное количество\n",
    "date_counts = dates.size()\n",
    "date_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion Date\n",
       "06/07/2016    384\n",
       "10/14/2011    391\n",
       "08/17/2017    392\n",
       "10/11/2017    392\n",
       "11/12/2013    401\n",
       "10/14/2016    412\n",
       "10/07/2011    457\n",
       "07/06/2016    461\n",
       "11/01/2013    488\n",
       "09/09/2016    492\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сортируем количества\n",
    "date_counts.sort_values()[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, _____ года у крыс был трудный денек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas – это большая библиотека, в которой намного больше возможностей, чем\n",
    "мы можем здесь описать. \n",
    "\n",
    "Если вам требуется анализировать большие наборы данных, группировать данные, обсчитывать статистику и т. п., то обязательно присмотритесь к ней.\n",
    "\n",
    "В книге Python for Data Analysis Уэса Маккинни (O'Reilly) также содержится много информации по этой теме."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
